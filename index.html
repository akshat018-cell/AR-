<!DOCTYPE html>
<html>

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>WebAR Wedding Invitation</title>

    <!-- A-Frame v1.5.0 -->
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <!-- MindAR v1.2.5 -->
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>

    <style>
        body {
            margin: 0;
            overflow: hidden;
        }

        #start-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.85);
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 9999;
            cursor: pointer;
            color: #fff;
            font-family: sans-serif;
            text-align: center;
            flex-direction: column;
        }

        #start-overlay h1 {
            font-size: 24px;
            margin-bottom: 10px;
        }

        #start-overlay p {
            font-size: 16px;
            opacity: 0.8;
        }

        .hidden {
            display: none !important;
        }
    </style>
</head>

<body>
    <div id="start-overlay">
        <h1>Tap to Start AR</h1>
        <p>Enable camera &amp; audio access</p>
    </div>

    <a-scene mindar-image="imageTargetSrc: ./targets.mind; filterMinCF:0.0001; filterBeta:0.001;" color-space="sRGB"
        renderer="colorManagement:true, physicallyCorrectLights" vr-mode-ui="enabled:false"
        device-orientation-permission-ui="enabled:false">

        <a-assets>
            <video id="invitation-video" src="./video.mp4" preload="metadata" loop crossorigin="anonymous" playsinline
                webkit-playsinline muted>
            </video>
        </a-assets>

        <a-camera position="0 0 0" look-controls="enabled:false"></a-camera>

        <a-entity id="target-entity" mindar-image-target="targetIndex:0">
            <a-plane id="video-plane" position="0 0 0" height="1.777" width="1" rotation="0 0 0"
                material="src: #invitation-video; transparent: true; side: double;">
            </a-plane>
        </a-entity>
    </a-scene>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const overlay = document.getElementById('start-overlay');
            const video = document.getElementById('invitation-video');
            const target = document.getElementById('target-entity');
            const plane = document.getElementById('video-plane');
            const scene = document.querySelector('a-scene');

            let audioUnlocked = false;

            // Apply chroma key AFTER scene loads
            scene.addEventListener('loaded', () => {
                console.log('Scene loaded, applying chroma key');

                const mesh = plane.getObject3D('mesh');
                if (mesh && mesh.material) {
                    const videoTex = new THREE.VideoTexture(video);
                    videoTex.minFilter = THREE.LinearFilter;
                    videoTex.magFilter = THREE.LinearFilter;

                    const chromaMaterial = new THREE.ShaderMaterial({
                        uniforms: {
                            map: { value: videoTex },
                            keyColor: { value: new THREE.Color(0.0, 1.0, 0.0) },
                            threshold: { value: 0.4 }
                        },
                        vertexShader: `
              varying vec2 vUv;
              void main() {
                vUv = uv;
                gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
              }
            `,
                        fragmentShader: `
              uniform sampler2D map;
              uniform vec3 keyColor;
              uniform float threshold;
              varying vec2 vUv;
              
              void main() {
                vec4 texColor = texture2D(map, vUv);
                float diff = distance(texColor.rgb, keyColor);
                
                if (diff < threshold) {
                  discard;
                } else {
                  gl_FragColor = texColor;
                }
              }
            `,
                        transparent: true,
                        side: THREE.DoubleSide
                    });

                    mesh.material = chromaMaterial;
                    console.log('Chroma key applied');
                }
            });

            // iOS audio fix
            overlay.addEventListener('click', () => {
                overlay.classList.add('hidden');
                video.play().then(() => {
                    video.pause();
                    video.currentTime = 0;
                    video.muted = false;
                    audioUnlocked = true;
                    console.log('Audio unlocked');
                }).catch(err => console.warn('Audio unlock failed:', err));
            });

            // AR events
            target.addEventListener('targetFound', () => {
                console.log('Target found');
                if (audioUnlocked) {
                    video.play();
                } else {
                    video.muted = true;
                    video.play();
                }
            });

            target.addEventListener('targetLost', () => {
                console.log('Target lost');
                video.pause();
            });
        });
    </script>
</body>

</html>